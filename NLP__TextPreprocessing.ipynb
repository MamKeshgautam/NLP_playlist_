{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvMOqJBBKxJy9SQG/AsU6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MamKeshgautam/NLP_playlist_/blob/main/NLP__TextPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#text Preprocessing"
      ],
      "metadata": {
        "id": "XO8nOAeuv0Cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bTq0ob4rvyNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install q kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzO_3M7vwL65",
        "outputId": "a5b4639e-c3de-45ea-def0-cc9aaa69d751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting q\n",
            "  Downloading q-2.7-py2.py3-none-any.whl.metadata (811 bytes)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n",
            "Downloading q-2.7-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: q\n",
            "Successfully installed q-2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HmCajSiUxCvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "nEo4Hla0xHpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import autoviz\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "SIA2s7XzxMEG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "DfaxGpdLxefd",
        "outputId": "52fc60b1-eb2b-4423-e5db-9115d74c74ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ed0cb56-8ab9-4181-ab59-e841cf292534\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ed0cb56-8ab9-4181-ab59-e841cf292534\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mamkeshgautam\",\"key\":\"9afa8bc1139e47273aed453810cdf582\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle  # make a folder in user directory"
      ],
      "metadata": {
        "id": "0J8wtekgxvNi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/  # Copy kaggle Api credential to folder"
      ],
      "metadata": {
        "id": "uw2zV_TJyANK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json # change the permission"
      ],
      "metadata": {
        "id": "TUCrpYTzyaTk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiGix5XQykEc",
        "outputId": "bd2163fb-fe2a-48d7-fb13-8f3f34f90980"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
            "License(s): other\n",
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 89% 23.0M/25.7M [00:01<00:00, 26.3MB/s]\n",
            "100% 25.7M/25.7M [00:01<00:00, 16.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip imdb-dataset-of-50k-movie-reviews.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibSjNSFc0nZX",
        "outputId": "9e6ad3cd-c7ce-4b1c-ebf3-1bd68a0d7c1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/IMDB Dataset.csv')"
      ],
      "metadata": {
        "id": "wYKf_V840vu9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # first do lowercasing"
      ],
      "metadata": {
        "id": "1ioMRdH02NDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Aj1bQFO017zt",
        "outputId": "35d380cc-8afc-4643-8ccb-749b0466c572"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'][3].lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "pYXDCTYx2HD5",
        "outputId": "788c16bc-11a6-4b03-97c3-fb59bb1a2684"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do in whole columns"
      ],
      "metadata": {
        "id": "1EUCHSwl2Ute"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']=df['review'].str.lower()"
      ],
      "metadata": {
        "id": "dDh6baPX2af2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE html TAG using Regx"
      ],
      "metadata": {
        "id": "_EBfgM_T2iO8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_html_tag(text):\n",
        "  pattern=re.compile('<.*?>')\n",
        "  return pattern.sub(r'',text)"
      ],
      "metadata": {
        "id": "kAjcWSPE3ljb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tags Remove"
      ],
      "metadata": {
        "id": "aq4cpCzTW5Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\"\n",
        "remove_html_tag(text) # this remove all tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "n90IAHK74lhI",
        "outputId": "cc8e59d4-8f7b-4fe9-d9df-30c7813dfaf1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']=df['review'].apply(remove_html_tag)"
      ],
      "metadata": {
        "id": "acFzSs9s43Pg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0iuvMTQ5Pdj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove URLs"
      ],
      "metadata": {
        "id": "xxahcnCV5djh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "  pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return pattern.sub(r'',text)"
      ],
      "metadata": {
        "id": "FVtEWh8-5gV4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review']=df['review'].apply(remove_url)"
      ],
      "metadata": {
        "id": "1a96KjmM6C6A"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ewwwXYKs6Hw5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Punctuation"
      ],
      "metadata": {
        "id": "97KM3ZvJ6gUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text): # NOT effective\n",
        "  import string\n",
        "  for punctuation in string.punctuation:\n",
        "    text=text.replace(punctuation,'')\n",
        "  return text"
      ],
      "metadata": {
        "id": "Lk-87UQV6pAO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start= time.time()\n",
        "\n",
        "df['review']=df['review'].apply(remove_punctuation)\n",
        "\n",
        "end=time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGN72ZV57FBp",
        "outputId": "19cff506-75f9-4481-eab2-354a36342a9b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7413687705993652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULyglAXS7NCz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Punc. effective way"
      ],
      "metadata": {
        "id": "ziW7RCc6ZaQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Remove_pun1(text):\n",
        "  return text.translate(str.maketrans('','',string.punctuation))"
      ],
      "metadata": {
        "id": "tSl_aZ0eXgp0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start= time.time()\n",
        "\n",
        "df['review']=df['review'].apply(Remove_pun1)\n",
        "\n",
        "end=time.time()\n",
        "print(end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZIk7uPhZ57h",
        "outputId": "21804d3e-0ed1-4706-dd77-6118a6f9a81c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6903290748596191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_hM2UL3Z_wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat word treatment\n"
      ],
      "metadata": {
        "id": "3d83imw_aW9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_conversion(text):\n",
        "  new_text=[]\n",
        "  for w in text.split():\n",
        "    if w.upper() in chat_word.keys():\n",
        "      new_text.append(chat_word[w.upper()])\n",
        "    else:\n",
        "      new_text.append(w)\n",
        "  return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "LwoSwjkQabBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spelling correction"
      ],
      "metadata": {
        "id": "rZNDTwjEbVfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "_H7kszmxbaET"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text='ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
        "textBlb=TextBlob(incorrect_text)\n",
        "textBlb.correct().string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MjVfV-S2bjEr",
        "outputId": "d6e0cb95-bb65-4ee0-ffef-53f403b4a03a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'certain conditions during several generations are modified in the same manner.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_cZ79XzcEg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop words"
      ],
      "metadata": {
        "id": "W49AWveBcJbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7152PAscNxn",
        "outputId": "2fda5410-9daa-4479-9946-fbe9ee2d1358"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT5-77ETcYtU",
        "outputId": "d237529d-6ce9-42ce-9830-297462049aea"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "  new_text=[]\n",
        "  for word in text.split():\n",
        "    if word in stopwords.words('english'):\n",
        "      new_text.append('')\n",
        "    else:\n",
        "      new_text.append(word)\n",
        "  x=new_text[:]\n",
        "  new_text.clear()\n",
        "  return \" \".join(x)\n",
        ""
      ],
      "metadata": {
        "id": "Flh7NSAhcnbZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=stopwords.words('english')[:5]"
      ],
      "metadata": {
        "id": "8kzyvUInd5Dl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvtGNMMEd9sa",
        "outputId": "3df1b2f2-57b2-42e8-f480-56bffb41a276"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emoji remove"
      ],
      "metadata": {
        "id": "qMo2gLuceMiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji # install emoji first\n",
        "import emoji\n",
        "print(emoji.demojize('Python is 👍'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNBfkjzueA1U",
        "outputId": "50099a38-bc06-4608-9e19-75f4ba130af4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n",
            "Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.12.1\n",
            "Python is :thumbs_up:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization : breaking sentances into small parts"
      ],
      "metadata": {
        "id": "b44MFe_jfua7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prefix\n",
        "# suffix\n",
        "# Infix\n",
        "#exception: Special_case several tokens or prevent a token from being split wheen punctuation rules are applied"
      ],
      "metadata": {
        "id": "FMeUsukVfaG-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen1 = \"Let's see how tokenization is done!\"\n",
        "sen1.split()\n",
        "# split functions fails in most of the senario"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reIviLMbiA1Z",
        "outputId": "4856c747-c8d1-4459-d355-ba3368c8768b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Let's\", 'see', 'how', 'tokenization', 'is', 'done!']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJEIkqGOiaSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 2: Use Regular *expression*"
      ],
      "metadata": {
        "id": "Zxk88B7IitL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sent3=\"Let's see how tokenization is done!\"\n",
        "tokens=re.findall(\"[\\w']+\",sent3)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPHyg9eGiymb",
        "outputId": "ea2da209-d0c7-4276-a01f-a1c3f54fed93"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Let's\", 'see', 'how', 'tokenization', 'is', 'done']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK"
      ],
      "metadata": {
        "id": "FPXIm_EjjHtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8yXTbVWi-Q_",
        "outputId": "d7839917-01ef-4fd2-8628-e333b0f62e60"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = \"Let's see how tokenization is done!\"\n",
        "word_tokenize(sent1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd8r0yDejRCp",
        "outputId": "4af80de1-bbd1-4593-83b3-154bcb6783af"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Let', \"'s\", 'see', 'how', 'tokenization', 'is', 'done', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.\n",
        "The sky is pinkish-blue. You shouldn't eat cardboard\"\"\"\n",
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSeZOuGEjUVl",
        "outputId": "fea08e0b-4498-47ff-d99a-25db8d1519f0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello Mr. Smith, how are you doing today?',\n",
              " 'The weather is great, and city is awesome.',\n",
              " 'The sky is pinkish-blue.',\n",
              " \"You shouldn't eat cardboard\"]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKX9xsD2kU-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# one the best lib. is spacy"
      ],
      "metadata": {
        "id": "lmB-mr2kkjWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "CUTvqTU0knn6"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "dlDo_p9tkqi_"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent3=nlp(\"Let's see how tokenization is done!\")\n",
        "for token in sent3:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48muY-IjlUbx",
        "outputId": "8d2e0f8a-36bf-4690-a82b-2f661eeb8e38"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let\n",
            "'s\n",
            "see\n",
            "how\n",
            "tokenization\n",
            "is\n",
            "done\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYR4o7R-l3JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "r42_i0twmIyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "wwXzcM-hmLAa"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps=PorterStemmer()\n",
        "def stem_words(text):\n",
        "  return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "wghc5rLDm6mB"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hoe19Rr4nJ1d"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent=\"walked,walks,walking\"\n",
        "stem_words(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tSXnTQWcnn7H",
        "outputId": "1e40dbfe-c6c0-49ee-fe9c-26f5a1e06eaf"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walked,walks,walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "goku=\"Son Goku[nb 20] probably is a fictional character and the main protagonist of the Dragon Ball manga series created by Akira Toriyama. He is based on Sun Wukong (known as Son Goku in Japan and Monkey King in the West), a main character of the classic 16th-century Chinese novel Journey to the West, combined with influences from the Hong Kong action cinema of Jackie Chan and Bruce Lee. Goku made his debut in the first Dragon Ball chapter, Bulma and Son Goku,[nb 21][nb 22] originally published in Japan's Weekly Shōnen Jump magazine on December 3, 1984.[2] Goku is introduced as an eccentric, monkey-tailed boy who practices martial arts and possesses superhuman strength. He meets Bulma and joins her on a journey to find the seven wish-granting Dragon Balls. Along the way, he finds new friends who follow him on his journey to become stronger. As Goku grows up, he becomes the Earth's mightiest warrior and battles a wide variety of villains with the help of his friends and family, while also gaining new allies in the process.\""
      ],
      "metadata": {
        "id": "A0cuvv5xnyWE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words(goku)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "iCgQlL9woxrJ",
        "outputId": "2def0433-42e2-43f6-e960-af8db354cd63"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"son goku[nb 20] probabl is a fiction charact and the main protagonist of the dragon ball manga seri creat by akira toriyama. he is base on sun wukong (known as son goku in japan and monkey king in the west), a main charact of the classic 16th-centuri chines novel journey to the west, combin with influenc from the hong kong action cinema of jacki chan and bruce lee. goku made hi debut in the first dragon ball chapter, bulma and son goku,[nb 21][nb 22] origin publish in japan' weekli shōnen jump magazin on decemb 3, 1984.[2] goku is introduc as an eccentric, monkey-tail boy who practic martial art and possess superhuman strength. he meet bulma and join her on a journey to find the seven wish-grant dragon balls. along the way, he find new friend who follow him on hi journey to becom stronger. as goku grow up, he becom the earth' mightiest warrior and battl a wide varieti of villain with the help of hi friend and family, while also gain new alli in the process.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4Urs691o1Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lamitazation"
      ],
      "metadata": {
        "id": "KePwGW0ppFpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet_lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "sentance=\"He was running and eating at same time. He has bad habit of swimming\"\n",
        "punc=\"?:!.,;\"\n",
        "sentence_words=nltk.word_tokenize(sentance)\n",
        "\n",
        "for word in sentence_words:\n",
        "  if word in punc:\n",
        "    sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "  print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos=\"v\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epRRZ2WOpInm",
        "outputId": "d42198f3-ea41-4b48-ffcf-ac7cc447edaa"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "He                  He                  \n",
            "was                 be                  \n",
            "running             run                 \n",
            "and                 and                 \n",
            "eating              eat                 \n",
            "at                  at                  \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 have                \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swim                \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IypibmALp5dq"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8S0JhSfp5_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}